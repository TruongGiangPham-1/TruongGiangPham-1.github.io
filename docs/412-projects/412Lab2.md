---
layout: page
title: CMPUT 503 Lab 2 report
permalink: 412-projects/A2/
date: 2025-02-12 10:33:00 -0000
---


# Ros Basics
**ROS topics**
Topics are named data buses where nodes can publish to. ROS uses publisher/subscriber patterns in which a node can publish date to a topic, and other nodes can subscribe to the same topic to receive published data through a callback. It is similar to a polling system.

**ROS nodes**
A node is a process instance that communicates with other nodes through topics and messages.
Each node is usually responsible for controlling a specific sensor or to do a specific task.

**ROS services**
The subscriber/publish model does not support one-to-one communication. ROS services allows request/reply communication model similar to client/server model.
A node can request for information from another node using services

**ROS messages**
ROS nodes publish messages to topics. ROS message can be primitive data types like float, int, boolean, etc, or a complex data types like arrays. ROS message can contain a header to include meta datas.

**ROS bags**
rosbag is a node that records data from topics that it subscribes for offline analysis.
We use `rosbag record` to start recording datas from specified subcribed topics.

**How it works together**

**Camera annotation**
<img src="{{site.baseurl}}/assets/images/camera_annotate.jpg" alt="camera" width="100%" height="auto">
We subscribed to `../camera_node/image/compressed` topic, and we let OpenCV does the grayscaling. 
We published to the same topic.

**Challenges**
Initially, `rqt_imag_view` did not render the grayscale image correctly. We realized later that grayscaling the image removes the last channel. 
`(H, W, 3) -> (H, W)`.
After reshaping the image back to `(H, W, 3)` using `gray_image = np.stack((gray_image,)*3, axis=-1)`, it works. 
On aside, we couldn't figure out how to publish to our own custom topic. 
Any topic aside from `../camera_node/image/compressed` caused image corruption.


# Making the robot move
<video controls style="width: 100%; height: 80%;">
    <source src="{{ site.baseurl }}/NA.mp4" type="video/mp4", alt="duckibotMove">
    Your browser does not support the video tag.
</video>
**Robot Kinematics**  
Since we did not have each wheel's velocity to compute $$\Delta\theta$$, we opt to compute it using only change in distance. 
We reference equations in [this medium article.](https://medium.com/@nahmed3536/wheel-odometry-model-for-differential-drive-robotics-91b85a012299)
<img src="{{site.baseurl}}/assets/images/wheel_odometry.png" alt="wheel_diagram" width="100%" height="auto">
We keep track of the world's frame $$[x_I, y_I, \theta_I]$$ at each timestep by mapping from robot's frame $$[x_r, y_r, \theta_r]$$.
We assume that $$\theta_r = \theta_I$$.  
$$d_w$$ is the distance between the wheel and the center of robot. 
We get this from rosparam  `/kinematics_node/baseline`.  
$$[x_I, y_I, \theta]_t = [x_r, y_r, \theta_r] \cdot R^{-1} (\theta)^T $$  
Where 

$$
R^{-1} (\theta)^T = \begin{bmatrix}
  cos(\theta) & sin(\theta) & 0 \\
  -sin(\theta) & cos(\theta) & 0 \\
  0 & 0 & 1
\end{bmatrix}
$$


$$
d = R\cdot \Delta\theta
$$

$$ 
d_{L} = (R - d_w) \cdot \Delta\theta  = R\cdot \Delta\theta - d_w \cdot \Delta\theta  \qquad (1)
$$

$$ 
d_{R} = (R + d_w)\cdot \Delta\theta = R\cdot \Delta\theta + d_w \cdot \Delta\theta  \qquad (2)
$$

We solve for this system of linear equation by multiplying (1) with -1

$$
\begin{align*}
  & -d_{L} = -R\cdot \Delta\theta + d_w \cdot \Delta\theta  \\
+ & d_{R} =  R\cdot \Delta\theta + d_w \cdot \Delta\theta \\
\hline
  & d_R - d_L = 2\cdot d_w \Delta\theta
\end{align*}
$$

Thus
$$
\Delta\theta = \frac{d_R - d_L}{2\cdot d_w}
$$
$$
\Delta\ x = \frac{d_R + d_L}{2}
$$
$$
\Delta\ y = 0
$$

All together,

$$
[x_I, y_I, \theta]_t = [x_I, y_I, \theta]_{t - 1} + R^{-1} (\theta)^T \cdot[\Delta x, 0, \Delta\theta]
$$

**Challenges**
* We struggle to compute the $$\Delta\theta$$ initially since it required each wheels' velocity.
We were eventually able to find formlas to compute $$\Delta\theta$$ using only distance traveled by each wheel, which can be computed using ticks.
* Since we had to update the change in robot frame in the background. We opt to put these calculations in a while loop, running in a separate threads. 
We could've calculate these in a callback, but we could not find information on a realiable topic to do attach a callback to do calculations.
* We realize that our calculated $$\Delta\theta$$ was smaller than expected. Therefore, we did  $$\Delta\theta = 1.5 cdot \theta$$ to scale to the expected value.
* The bot does not drive in a straight line despite retuning the trim value. We can overcome it by making publishing an imbalance velocity to each wheel to correct it.
### Why is there difference between the actual and desired location?
Perhaps there was difference in the theoretical and the actual robot location is because of the discrepancies in tick encoder sensors or other constants. We did not measure the wheel radius nor the distance between the wheels, so we used the default value in the kinematic file (0.325 and 1). On aside, terraine fraction can also mess up with our maths.

### What speed did you use? What happens when you increase or decrease the speed?
We used constant 0.5 velocity for each wheels. When we increased the speed, we find that the duckiebot is more stable. Perhaps it overcame small bumps on the terrain that could otherwise affect the wheels.

# Turn the Duckiebot
<video controls style="width: 100%; height: 80%;">
    <source src="{{ site.baseurl }}/NA.mp4" type="video/mp4", alt="duckibotTurn">
    Your browser does not support the video tag.
</video>
To spin duckiebot, we spun each wheel in the oppostie direction. 
Since we accumulate the rotation angle, we stop when the difference between the angle is above $$\pi/2$$

**Challenges**
hello

### What could be the cause of deviations in the rotation?
It could be any of the followings:
* Wheels slipping
* Uneven motors (ticks are accumulated at an uneven rate)
* Frictions
These small errors compound overtime to cause larger deviations

### Plotting the tracjed trajectory
<img src="{{site.baseurl}}/assets/images/NA.png" alt="bag trajectory" width="100%" height="auto">
Place holder

### Duckiebot Pathing
<video controls style="width: 100%; height: 80%;">
    <source src="{{ site.baseurl }}/NA.mp4" type="video/mp4", alt="duckibotDshape">
    Your browser does not support the video tag.
</video>

